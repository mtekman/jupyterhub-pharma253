#+TITLE: Pharma2-53 JupyterHub Server with personalised DockerSpawner

* What is this

This is a JupyterHub configuration and extension of the original spec
which displays metrics to users on the system resources, spawns Docker
containers, and preserves the existing conda/mamba environments in
each user directory.

The idea is to restrict all the different Jupyter kernels running on
the same system from competing too hard on RAM resources.

It has also been customized towards the Institute of Pharmacology and
Toxicology at the University Freiburg.

* System Security and Resources

Before we expose a powerful machine to the internet and unleash it on
a few dozen users, we need to set some boundaries.

** Configure Docker

First we need to enable Docker, and make note of the network it makes,
since this is information needed in the Jupyter configuration file.

*** Extract Docker Subnet

First check the current addresses:
#+begin_src bash
  > ip a
  1: lo:....
     .....
     inet 127.0.0.1/8
     ...
  2: eth0: ....
     ....
     inet blahblahblah/24 ....
     ....
  3: eth1: ...
     ....
     inet blahblahblah/24 ....
     ...    
#+end_src

we don't see any network device starting with "docker", so we need to start docker

#+begin_src bash
  > sudo systemctl start docker
  > ip a
  1: lo ...
  2: eth0 ...
  3: eth1 ...
  4: docker0 ...
     ...
     inet 172.17.0.1/16   
#+end_src

This is what we want to see, the inet address of the =docker0= device, =172.17.0.1=.
Remember this, we will use this for later.
   
** Firewall

[[https://wiki.archlinux.org/title/Uncomplicated_Firewall][UFW]] (Uncomplicated Firewall) is a great firewall for blocking unwanted
connections. The Pharma2-53 is already behind a firewall and does not
accept outside connections from the facility

You can verify this by looking at the output of

#+begin_src bash
> sudo ufw status
Status: active

To                         Action      From
--                         ------      ----
137/udp                    ALLOW       blahblahblah/24
138/udp                    ALLOW       blahblahblah/24
139/tcp                    ALLOW       blahblahblah/24
445/tcp                    ALLOW       blahblahblah/24
137/udp                    ALLOW       blahblahblah/24
138/udp                    ALLOW       blahblahblah/24
138/tcp                    ALLOW       blahblahblah/24
445/tcp                    ALLOW       blahblahblah/24
22/tcp                     ALLOW       blahblahblah/24
22/tcp                     ALLOW       blahblahblah/24
22/tcp                     ALLOW       blahblahblah/16
#+end_src

At this point, any Docker containers that we make will be blocked by
the system, so we need to create a new allow rule.

(Note: the machine you are using to SSH into the Pharma2-53 device,
 *should* share the prefix of one of the From addresses in the list
 above, otherwise you will lose ssh access in the next step.)

#+begin_src bash
  > sudo ufw allow from 172.17.0.0/16
  > sudo ufw status
  ...
  ...  
  Anywhere                   ALLOW       172.17.0.0/16
#+end_src

Now we see that we have added an allow exception rule for the docker0 device.

** Allowed SSH users

Jupyter allows authenticated users to execute commands by offering
them a terminal they can use. For this reason, it does not make sense
to offer all users the ability to SSH into the machine, since they
could wreak havoc on the services there.

We adjust the allowed ssh users by modifying =/etc/ssh/sshd_config=,
and changing the line to:

#+begin_src conf
      AllowUsers user1 user2 user3
#+end_src

where these correspond to trusted admin usernames on the system

We then restart ssh to refresh these changes

#+begin_src bash
  sudo systemctl restart ssh
#+end_src

* Jupyter Installation

With the system configured for Docker and Security, we can proceed
with the Jupyter Installation.

The installation comes in two parts:

1. Installing the modified Jupyter base installation
   
   The original jupyterhub does not freely offer metrics on a per-user
   basis, so I forked their repository and implemented it myself.

   That is, we are not using vanilla JupyterHub, but JupyterHub+Metrics.

2. Installing a custom Docker Spawner

   A spawner is what Jupyter uses to create kernels (essentially
   notebooks) for each user. There are many [[https://jupyterhub.readthedocs.io/en/stable/reference/spawners.html][different types]], but the
   one we are interested in is the [[https://jupyterhub-dockerspawner.readthedocs.io/en/latest/spawner-types.html][SystemUserSpawner]] which is a type
   of DockerSpawner (which is a kernel that creates Docker containers,
   instead of running everything as a single process on the machine).

   Unfortunately, the SystemUserSpawner restricts kernels equally,
   meaning that all users get the same requirements. This is good if
   users all have the same demands, but typically they don't.

   Fortunately, one can extend SystemUserSpawner into a custom class I
   wrote called =DockerSystemProfileSpawner= which allows per-user
   customization, and we will go into detail about how to configure it later.

** Backup Existing installation

First thing's first, we backup any existing Jupyter installation. On
the Pharma2-53 machine, this involves stopping the existing JupyterHub
service and moving any config files to a backup location:

#+begin_src bash  
  sudo systemctl stop jupyterhub
  sudo mkdir /opt/__<date>_jupyter_backup
  sudo mv /etc/systemd/system/jupyterhub.service /opt/__<date>_jupyter_backup/
  sudo mv /opt/jupyterhub/* /opt/__<date>_jupyter_backup/
#+end_src

** Prepare custom dependencies

The JupyterHub that we will be installing is based on version
=5.0.0.dev= which is pretty new as of 2024-03-13.

It needs up-to-date Node and Python libraries, which are not a problem
for bleeding edge Operating systems like Arch Linux, but *is* a
problem for more stable OS's like Ubuntu.

*** Node

We upgrade the Node libraries in Ubuntu via

#+begin_src bash
  sudo apt-get update && sudo apt-get install -y ca-certificates curl gnupg
  curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg
  export NODE_MAJOR=21
  echo "deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_$NODE_MAJOR.x nodistro main" | sudo tee /etc/apt/sources.list.d/nodesource.list
  sudo apt-get update && sudo apt-get install nodejs -y
#+end_src

Verify that we are on version 21 via

#+begin_src bash
  node --version
#+end_src

*** (Optional) Python

The version of JupyterHub we're using relies on a pretty modern
Python. To avoid any discrepancies between system Python and Jupyter
Python, we will build our own Python, seperate from the system.

  #+begin_src bash
    export MYPYVER=3.11.8
    export INSTALLHERE=/opt/jupyterhub/python-${MYPYVER}  ## must be an absolute path

    ## Get and unpack python sources
    cd /opt/jupyterhub
    wget http://www.python.org/ftp/python/${MYPYVER}/Python-${MYPYVER}.tgz
    tar -zxvf Python-${MYPYVER}.tgz

    ## specify installation directory
    mkdir ${INSTALLHERE}
    cd Python-${MYPYVER}
    CXX=$(command -v g++) ./configure --prefix=${INSTALLHERE} --enable-optimizations --enable-loadable-sqlite-extensions
    make
    make install

    ## Remove unneeded source files
    rm -rf /opt/jupyterhub/Python-${MYPYVER}.tgz /opt/jupyterhub/Python-${MYPYVER}
  #+end_src

** Prepare Jupyter


At this point we have 1 directory

#+begin_src bash
    > tree  /opt/jupyterhub
    /opt/jupyterhub/
    └─ python-3.11.8
#+end_src

We need to prepare the other directories now, the custom Jupyter
install, and the custom DockerSpawner.

*** Prepare Jupyter Directories

  Let's clone the needed repos

**** DockerSystemProfileSpawner

+ Clone this repo...

#+begin_src bash
  cd /opt/jupyterhub
  git clone https://gitlab.com/mtekman/jupyterhub-pharma253
#+end_src

**** Jupyter with Metrics

We do a shallow clone and use the "sysmon" branch

#+begin_src bash
  cd /opt/jupyterhub
  git clone --depth 1 https://github.com/mtekman/jupyterhub/ -b sysmon jupyterhub-metrics
#+end_src

At this point we now have 3 directories

#+begin_src bash
  > tree  /opt/jupyterhub
  /opt/jupyterhub/
  ├─ jupyterhub-metrics    (our custom jupyterhub)
  ├─ jupyterhub-pharma253  (the custom docker spawner)
  └─ python-3.11.8         (our custom python)
#+end_src


*** Creating the Jupyter VirtualEnvironment

We built our own Python previously in the
=/opt/jupyterhub/python-3.11.8= directory, but we haven't actually
used it yet or installed any necessary packages into it.

To do so, we create a virtual environment from it, and we keep it
inside the the pharma directory.

#+begin_src bash
  cd /opt/jupyterhub/jupyterhub-pharma253
  /opt/jupyterhub/jupyterhub-metrics/bin/python -m virtualenv venv_jupyter_metrics
#+end_src

Now we *source* this environment. We install packages inside of it and use it for launching Jupyter.

#+begin_src bash
  source venv_jupyter_metrics/bin/activate  ## we've sourced it
  pip install ../jupyterhub-metrics/        ## install the dependencies of jupyter
  pip install dockerspawner psutil configurable-http-proxy  ## install other dependencies
#+end_src

At this point Jupyter with metrics is installed. We just need to configure it.


* Jupyter Config file

The config file is actually a python script, so we use it to import
our custom spawner, and to configure the different components of the Hub.

Ignore the first few lines, these just tell python to consider the
current directory when looking for modules.

*** Jupyter Venv

You should set the =jupyter_venv= variable to the absolute path of the
=venv_jupyter_metrics= virtual environment we made earlier

#+begin_src python
  jupyter_venv = "/opt/jupyterhub/jupyterhub-pharma253/venv_jupyter_metrics/"
#+end_src

*** Admin Users

We need to define our admin users who will have permissions to oversee
the server and access the servers of other users.

#+begin_src python
  c.Authenticator.admin_users = ['memo', 'admin']
#+end_src

Here we define two users: "memo" and "admin" which are valid system user accounts.

** Server Type

We also need to tell Jupyter what kind of server this is by setting
the =server_type= variable.

1. "local"

   Jupyter will be served only on the local machine over an insecure http protocol.

   If you wish to still use this server as is, but open it up to the
   entire network, then change the =c.JupyterHub.ip= variable near the
   bottom to "0.0.0.0".

2. "https"

   Jupyter will be served over the internet over a secure https protocol.

   You will need to configure the =c.JupyterHub.ssl_cert= and
   =c.JupyterHub.ssl_key= variables with your HTTPS certificate
   fullchain and privkeys that you will get from certbot. See the
   [[HTTPS Certification]] section later.

3. "proxy"

   Jupyter will be server over the internet through a secure
   proxy. Users will not connect directly to this machine, but will
   connect first to a proxy device, and the proxy device will tunnel
   all requests to the machine.

   The certificates do not matter here, since all certification is
   performed on the proxy machine and not on the Jupyter machine.

   You will need to configure the =c.JupyterHub.bind_url= variable to point to the
   http proxy address and port. See the [[Proxy Machine]] section later.


The Pharma2-53 machine does not allow for direct outside connections
(see the [[Firewall]] section previously). So either you make a few
exceptions to allow port 80 (http) and port 443 (https) in the
firewall, or we use the proxy option

#+begin_src python
  server_type = "proxy"
#+end_src

** Managing Individual User Resources

This section describes the way we can configure what resources are
offered to the users. The recommended CPU and MEM profiles, with
maximum limits, the Docker images they can use, and the per-user overrides.

*** Resource Profiles

Here we set 5 resource profiles that users can choose from, defined by
how many CPU cores and how many GB's of RAM they can consume.

#+begin_src python
  c.JupyterHub.spawner_class.resource_profiles = {
      ## These are maximum LIMITs to which a Docker Image can run.
      ## - At the same time, you can PREALLOCATE resources, see the preallocate
      ##   subentry in the user_profiles
      "Tiny"   : {"cpu_limit": 1,  "mem_limit": 2},
      "Small"  : {"cpu_limit": 2,  "mem_limit": 4},
      "Normal" : {"cpu_limit": 5,  "mem_limit": 10},
      "Large"  : {"cpu_limit": 10, "mem_limit": 40},
      "Extreme": {"cpu_limit": 36, "mem_limit": 80}
  }
#+end_src

These are maximum limits, and the user can manually select whatever
resources they want that fit their allowed resource profiles.

Users can also have "preallocated" cores and memory, meaning that at
*minimum* a certain number of cores and memory will allocated for them.

*** Docker Profiles

Here we define 3 different docker images (each containing a
jupyter-*lab* install), and the URLs to retrieve them.

You can find more jupyter docker "stacks" [[https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-base-notebook][here]].

#+begin_src python
  c.JupyterHub.spawner_class.docker_profiles = {
      ## These correspond quay.io images, but see
      ## https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-base-notebook
      ## for more
      ##
      ## Basic, users rely on their conda installations for software
      "SingleUser" : "quay.io/jupyterhub/singleuser:main",
      "BaseNotebook" : "quay.io/jupyter/base-notebook",
      ## Includes R, Python, and Julia at the system level, as well as their conda installations.
      "DataScience" : "quay.io/jupyter/datascience-notebook:latest"
      ## Add others
      ##
      ## To prevent users complaining of the slow startup times, download the required image first,
      ## and then run Jupyter.
      ## e.g. sudo docker run <URL>
  }
#+end_src

  The first time these images are fetched and built, they will take
  some time, so it is better to pre-emptively fetch these images
  before starting the server, so that the docker containers don't need to wait first.

  You can fetch them with the docker run command shown in the comment text above.

*** User Profiles

These are the individual user restrictions. Below we define two users "default" and "memo". 
By default all users use the "default" profile, unless explicitly named.

All keywords are named to be compliant with the [[https://jupyterhub-dockerspawner.readthedocs.io/en/latest/api/index.html][DockerSpawner API]].

#+begin_src python
  c.JupyterHub.spawner_class.user_profiles = {
      ## Docker profiles permitted per user.
      ##
      ## The "default" entry MUST exist. These are the docker profiles
      ## permitted to any user who isn't explicitly listed below. The
      ## first entry in the list, is the preferred profile first offered
      ## to the user in the selection screen.
      ##
      "default" : {
          "allowed_resources": ["Normal", "Tiny", "Small", "Large", "Extreme"],
          "allowed_docker": ["SingleUser", "BaseNotebook", "DataScience"],
          "host_homedir_format_string" : "/media/daten/{username}",
          ## maximum guaranteed resources for default users
          ## - if the requested are smaller than the resource profile
          ##   then these are scaled down to that profile.
          "max_preallocate" : {"cpu_guarantee" : 5, "mem_guarantee": 10 }},

      ## User overrides
      "memo" : { "allowed_resources" : ["Normal", "Tiny", "Small"],
      ##"allowed_docker" : ["SingleUser"],  ## must be an array, not string or tuple
                "max_preallocate" : {"cpu_guarantee" : 2, "mem_guarantee": 4 },
                ##"host_homedir_format_string" : "/opt/jupyterhub/user_home/jupyter_users/{username}"}
                ## Note that conda only works when home directories are set...
                "host_homedir_format_string" : "/home/{username}"}
      ##
      ## Note: The allowed profile with the largest RAM and largest
      ## number of CPUs is the upper limit on what the HTML sliders will
      ## permit.
      }

#+end_src

 - By default all users are allowed to use all the resource profiles
defined above, via the =allowed_resources= variable. Notice how user
"memo" can only use 3 of those profiles..

- Similarly one can define allowed docker images via the
=allowed_docker= variable. Since the user "memo" does not have this
defined, he defaults to whatever the "default" user specifies for that
variable.

- The =host_homedir_format_string= *must* contain the placeholder
"{username}" string in it's path, and it defines where the home
directories of the users are, along with their conda environments. The
user "memo" has his home directory in /home/memo path, which is
different than the /media/daten/memo path that would have otherwise
been specified in the default user profile.

- The =max_preallocate= variable specifies the minimum preallocation
  of resources that are guaranteed for a user. These resources will
  then grow at maximum to whatever resource profile the user chooses
  when spawning a kernel.

** Testing Jupyter

With your config file setup, it is now time to test the server


*** Useful debug scripts
+ killing all docker, removing sqlite and cookie, starting as user
+ removing =rm -rf .jupyter .local/share/jupyter/ .cache=

** Running Jupyter


* Post Installation Steps

** Setup Proxy

*** Host Machine

*** Proxy Machine

**** WebServer

***** Caddy

***** Nginx

**** HTTPS Certification


** Set Global limits on Docker

We will be restricting individual Docker containers¹ for each user
later, but we also want to set a global limit on Docker in general so
that the rest of the OS still has some resources for itself.

1: A "docker image" is a small operating system file, and a "docker
   container" uses an image to create an environment, which correspond
   to Jupyter kernels.

We control the main docker process/daemon by making a child of a
[[https://en.wikipedia.org/wiki/Cgroups][control group]] which has resource quotas.

We will perform this step later. TODODODODOD


* Customization

+ Templates


* Troubleshooting

** Docker notebooks hang and do not spawn
+ Preload the images
+ Check the firewall
 
** Users cannot use their conda environments
+ Check image and host parameters
+ Check the home path
+ Remove all containers for a user, restart server

** Other issues

+ Make a PR